

## Kevin

- How exactly do I use tf learn experiment to call predict on this model. I think
  we just reconsturct the Experiment with the job/model dir and call predict on it

  NOTE: the priority is prediction with classic TF apis rather than the 
  `predict_local` function.

- Support 'job_output' + 'job_name' as alternative to 'job_dir'

- Job status/control functions

- job_collect / job_status / etc. all need to take either a job id/name or a job object
  (otherwise you can't ever get back to them if you don't have the live job object)

- using the 'cloudml' directory within the user's project and then recursively unlinking it
  seems very sketchy. We should use a more obscured name.

- Ensure python package enumerates files correctly
  https://github.com/rstudio/cloudml/commit/0c109336c366ada703ea563a1ddc806dab571cf9#commitcomment-21154573
  

## Cloud NEXT

- Sort out all of the gcloud sdk installation / authentication requirements
  for people other than us to use the package and document this well.

- Windows compatibility

- Documentation on using the package

- Pull out `hyperparameters` from config and write a new YAML file with:
    trainingInput:
       hyperparmeters:
  Then pass that to gcloud with --config hyperparmeters.yml
  
  Then in our app.R generated file where we set the config pacakge hook we 
  propagate the command line options/hyperparamters back into the config list



## Future

- install_gcloud_sdk function (see headless install in https://cloud.google.com/sdk/downloads)

- Include/exclude keys in config

- Online prediction

- Satisfying R package dependencies of train.R (packrat manifest + .Rprofile?)

- Package skeleton function w/ config.yml, train.R, etc.

- Build pane integration: Custom project type exposing various commands

- rstudioapi package making available a version of system that pumps events




