
## JJ


- Automatically call gs_data on all embedded GS URLs

- Generate the app.R file that includes the config hooks (do this in train_cloud)


## Kevin

- How to handle the project directory for packaging (copy, symlink, cleanup, etc.)
    - Never upload gs_data
    - Don't want to upload the job or staging dir (how can we ensure this?)
    - Should we even exppose by default the job_dir and staging dir in the config file
    - Cleanup __init__.py, etc. after we create the python package (on.exit)
    
- Provide some down-sampled local versions of data and have them referenced via e.g.
  gs://rstudio-cloudml-demo-ml/census/data/local.adult.test
  
- Pull out `hyperparameters` from config and write a new YAML file with:
    trainingInput:
       hyperparmeters:
  Then pass that to gcloud with --config hyperparmeters.yml
  
- Then in our app.R generated file where we set the config pacakge hook we 
  propagate the command line options/hyperparamters back into the config list
  

## Next

- Prediction API

- Job status/control functions

- Dataviz and/or Shiny app front-end

- What is returned by cloudml (minimially view it in stdout, for prediction structured data)




       
       

