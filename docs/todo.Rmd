

## JJ

- Create access token for installation of gcloud

- Python interrupt callback

## Kevin

- Need to figure out what happens to the exported model for both the local
  and gcloud case. How do I get my hands on the model?
  
- How exactly do I use tf learn experiment to call predict on this model

- Job status/control functions

- How to handle the project directory for packaging (copy, symlink, cleanup, etc.)
    - Never upload gs_data
    - Don't want to upload the job or staging dir (how can we ensure this?)
    - Should we even exppose by default the job_dir and staging dir in the config file
    - Cleanup __init__.py, etc. after we create the python package (on.exit)

- Pull out `hyperparameters` from config and write a new YAML file with:
    trainingInput:
       hyperparmeters:
  Then pass that to gcloud with --config hyperparmeters.yml
  
  Then in our app.R generated file where we set the config pacakge hook we 
  propagate the command line options/hyperparamters back into the config list


## Cloud NEXT

- Sort out all of the gcloud sdk installation / authentication requirements
  for people other than us to use the package and document this well.

- Documentation on using the package


## Future

- Package skeleton function w/ config.yml, train.R, etc.

- Online prediction

- Build pane integration: Custom project type exposing various commands



       
       

